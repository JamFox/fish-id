{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0c11e-d134-4b00-a08d-f73096b7784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import hub, tensor, device, cuda, unsqueeze\n",
    "from torchvision.io.video import read_video\n",
    "from torchvision import set_video_backend, transforms\n",
    "from nonmaxsupression import non_max_suppression\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "set_video_backend(\"pyav\")\n",
    "device = device(\"cuda\" if cuda.is_available() else \"cpu\")\n",
    "\n",
    "DEFAULT_IN_DIR = 'intro/videos'\n",
    "DEFAULT_OUT_DIR = 'bboxes'\n",
    "DEFAULT_MIN_CONF = 0.9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45d088fa",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4927ddb-a251-4aae-90a5-da395adbbc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading fish detection model from torch hub using custom trained weights\n",
    "weights='intro/annotations/models/last.pt'\n",
    "model = hub.load('ultralytics/yolov5', 'custom', path=weights,  _verbose=False)\n",
    "model = model.to(device)\n",
    "model = model.eval() #put model into evaluation / inference mode (not for training)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc3ead4c",
   "metadata": {},
   "source": [
    "## Define function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd381c-34a8-4f26-ad75-9e4bff936305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_bboxes(video_path, output_path, model, min_conf, device):\n",
    "    \"\"\"Exports png frames from video using bounding box information and prediction confidence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    video_path : str\n",
    "        Path to video to extract frames from.\n",
    "    output_path : str\n",
    "        Path where to extract frames to.\n",
    "    model : models.common\n",
    "        The torchvision.models subpackage imported or custom model to use for evaluating frames.\n",
    "    min_conf : float\n",
    "        The minimum prediction confidence percentage. Should be a value between 0 and 1.\n",
    "    device : torch.device\n",
    "        The device on which a torch.Tensor is or will be allocated (i.e. 'cpu' or 'cuda').\n",
    "    \"\"\"\n",
    "    # Make sure that output path exists\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    # Read the video and convert it to a PyTorch tensor\n",
    "    vid = read_video(video_path)[0].to(device)\n",
    "    # Get video name without file extension\n",
    "    base_name = os.path.basename(video_path)\n",
    "    base_name, ext = os.path.splitext(base_name)\n",
    "    \n",
    "    # Loop through each tensor frame in the video\n",
    "    for i, frame in enumerate(vid):\n",
    "        # Convert the frame to a PyTorch tensor\n",
    "        frame = unsqueeze(frame, 0)\n",
    "        # Resize the frame to 640x640 permuted to n_frames, H, W, C\n",
    "        frame = transforms.Resize((640, 640))(frame.permute(0,3,1,2))/255\n",
    "        # Apply non-maximum suppression to get the bounding box predictions\n",
    "        pred = non_max_suppression(model(frame))\n",
    "        \n",
    "        # Loop through each bounding box prediction\n",
    "        for p in pred:\n",
    "            # Skip if frame is empty\n",
    "            if len(p) == 0:\n",
    "                continue\n",
    "            # Extract the bounding box coordinates, confidence, and class\n",
    "            x1, y1, x2, y2, conf, cls = p[0]\n",
    "            # Skip if confidence is too low\n",
    "            if conf < min_conf:\n",
    "                continue\n",
    "            # Convert the bounding box coordinates from float to integer format\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            # Crop the frame using the bounding box coordinates\n",
    "            cropped_frame = frame[:, :, y1:y2, x1:x2]\n",
    "            # Convert the PyTorch tensor to a numpy array\n",
    "            np_frame = cropped_frame.permute(0,2,3,1).cpu().numpy()[0]\n",
    "            # Generate full path of image to be saved\n",
    "            output_full_path = output_path + '/' + f\"{base_name}_frame_{i}_bbox_{x1}_{y1}_{x2}_{y2}.png\"\n",
    "            \n",
    "            # Save image if it does not exist already\n",
    "            if not os.path.exists(output_full_path):\n",
    "                try:\n",
    "                    # Save the numpy array as a PNG image\n",
    "                    Image.fromarray(np.uint8(np_frame*255)).save(output_full_path)\n",
    "                # Improperly cropped frames may fail\n",
    "                # So we catch errors here to skip them\n",
    "                except Exception as e: print(f\"Error extracting frame {i} from {video_path}: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "482eb47e",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a5975-1adf-4cc6-b901-63aaee8646e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each directory under specified directory\n",
    "for dir_name, sub_dirs, files in os.walk(DEFAULT_IN_DIR):\n",
    "    # Loop over each file in the directory\n",
    "    for file_name in files:\n",
    "        # Generate full path to file\n",
    "        file_path = dir_name + '/' + file_name\n",
    "        # Check if the file ends with .avi extension\n",
    "        if os.path.splitext(file_name)[1] == '.avi':\n",
    "            # Extract bounding boxes from video\n",
    "            export_bboxes(file_path, DEFAULT_OUT_DIR + '/' + os.path.basename(dir_name), model, DEFAULT_MIN_CONF, device)\n",
    "print(\"Finished extracting bounding boxes!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
